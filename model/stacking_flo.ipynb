{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des donn√©es\n",
    "train_df = pd.read_csv('../data/cleaned_train.csv')\n",
    "test_df = pd.read_csv('../data/cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['count']\n",
    "X_train = train_df.drop(['count'], axis=1)\n",
    "y_test = test_df['count']\n",
    "X_test = test_df.drop(['count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 15 and input n_features is 13",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\ds\\vlib_ml_app\\model\\stacking_flo.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ds/vlib_ml_app/model/stacking_flo.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39m# Import XGB Florian\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ds/vlib_ml_app/model/stacking_flo.ipynb#ch0000003?line=2'>3</a>\u001b[0m xgb_flo \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlgb_best.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ds/vlib_ml_app/model/stacking_flo.ipynb#ch0000003?line=3'>4</a>\u001b[0m result \u001b[39m=\u001b[39m xgb_flo\u001b[39m.\u001b[39;49mscore(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ds/vlib_ml_app/model/stacking_flo.ipynb#ch0000003?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\base.py:705\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/sklearn/base.py?line=662'>663</a>\u001b[0m \u001b[39m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/sklearn/base.py?line=663'>664</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/sklearn/base.py?line=664'>665</a>\u001b[0m \u001b[39mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/sklearn/base.py?line=699'>700</a>\u001b[0m \u001b[39m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/sklearn/base.py?line=700'>701</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/sklearn/base.py?line=702'>703</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score\n\u001b[1;32m--> <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/sklearn/base.py?line=704'>705</a>\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/sklearn/base.py?line=705'>706</a>\u001b[0m \u001b[39mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\datascience\\lib\\site-packages\\lightgbm\\sklearn.py:800\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/lightgbm/sklearn.py?line=797'>798</a>\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/lightgbm/sklearn.py?line=798'>799</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features \u001b[39m!=\u001b[39m n_features:\n\u001b[1;32m--> <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/lightgbm/sklearn.py?line=799'>800</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumber of features of the model must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/lightgbm/sklearn.py?line=800'>801</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmatch the input. Model n_features_ is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/lightgbm/sklearn.py?line=801'>802</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput n_features is \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/lightgbm/sklearn.py?line=802'>803</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster\u001b[39m.\u001b[39mpredict(X, raw_score\u001b[39m=\u001b[39mraw_score, start_iteration\u001b[39m=\u001b[39mstart_iteration, num_iteration\u001b[39m=\u001b[39mnum_iteration,\n\u001b[0;32m    <a href='file:///c%3A/Users/flori/anaconda3/envs/datascience/lib/site-packages/lightgbm/sklearn.py?line=803'>804</a>\u001b[0m                              pred_leaf\u001b[39m=\u001b[39mpred_leaf, pred_contrib\u001b[39m=\u001b[39mpred_contrib, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 15 and input n_features is 13"
     ]
    }
   ],
   "source": [
    "# Import XGB Florian\n",
    "\n",
    "xgb_flo = pickle.load(open('lgb_best.pkl', 'rb'))\n",
    "result = xgb_flo.score(X_train, y_train)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "base_models = [('XGB', xgb_flo),\n",
    "               ]\n",
    "meta_model = LinearRegression()\n",
    "stacking_model = StackingRegressor(estimators = base_models, final_estimator = meta_model, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingRegressor(cv=2,\n",
       "                  estimators=[('XGB',\n",
       "                               LGBMRegressor(learning_rate=0.01,\n",
       "                                             n_estimators=1000))],\n",
       "                  final_estimator=LinearRegression())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stacking_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9152402670309673"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 0.9152402670309673\n",
      "mae 43.42827816141063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "print('r2', r2_score(y_test, y_pred))\n",
    "print('mae', mean_absolute_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd1cc886148b1d3dda72fea19e5fba9571a5a0d898d8fb89a58d1d381078e2c8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('devia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
